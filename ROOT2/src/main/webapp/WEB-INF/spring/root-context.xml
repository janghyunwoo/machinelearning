<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xmlns:hadoop="http://www.springframework.org/schema/hadoop"
	xsi:schemaLocation="http://www.springframework.org/schema/hadoop http://www.springframework.org/schema/hadoop/spring-hadoop.xsd
		http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd">
	
	<!-- Root Context: defines shared resources visible to all other web components -->
	
	<!-- HDFS 서버 정보 입력 -->
	<hadoop:configuration id ="hdConf">
			fs.default.name=hdfs://192.168.0.11:9000
	</hadoop:configuration>
	
	<!-- 처리할 작업 기술
		input-path = 입력시킬 파일의 위치. (HDFS상 경로이다)
		output-path = 출력시킬 파일의 위치. (HDFS상 경로이다)
		configuration-ref = HDFS 서버 정보의 ID 값
		mapper, reducer = 맵리듀스를 기술한 클래스 (패키지명.클래스명)
	 -->
 	<hadoop:job id="wordCountJob"
					input-path="/input/"
					output-path="/output/"
					configuration-ref="hdConf"
					mapper="com.jang.hadoop2.SubCMapper"
					reducer="com.jang.hadoop2.SCReducer"
					
	/>
	
	<!-- 작업을 직접 행동 할 객체
		job-ref = 이 객체가 처리할 작업의 ID
		run-at-startup = 실행 할 때 작업을 시작할 건지를 결정
	 -->
	<hadoop:job-runner id="wordCountJobRunner" job-ref="wordCountJob" run-at-startup="false"  />
</beans>
